{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 - Grid GBIF species"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in notebook 1.1, we want to query species composition from each grid cell location to compile species presence, count, and distance-weighted count for several different query radii. The most precise method for this job would be to use either R-trees or K-d trees to query species observations that intersect with the radii. For high-resolution rasters (10m and 20m) with such a broad spatial extent, however, this method requires significant computation time and/or memory usage. A quicker approach may be to approximate these precise queries through interpolation and either density thresholding or moving-window calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import rasterio\n",
    "\n",
    "from src.conf.parse_params import config as cfg\n",
    "from src.utils.df_utils import read_df\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "os.chdir(os.environ[\"PROJECT_ROOT\"])\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-tree-based approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import cupyx as cpx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from scipy.ndimage import gaussian_filter, generic_filter\n",
    "from scipy.signal import convolve2d\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from src.utils.df_utils import read_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbif = read_gdf(cfg[\"gbif\"][\"masked\"])\n",
    "\n",
    "# Subset to the most abundant species for quick testing\n",
    "top_species = gbif.species.value_counts().index[0]\n",
    "species = gbif[gbif.species == top_species]\n",
    "\n",
    "with rasterio.open(cfg[\"s2_20m\"][\"src\"]) as src:\n",
    "    target_meta = src.meta\n",
    "    target_shape = (src.height, src.width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple utility method to print the stats of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(data: np.ndarray) -> None:\n",
    "    results = stats.describe(data)\n",
    "    print(f\"Number of elements: {results.nobs}\")\n",
    "    print(f\"Min: {results.minmax[0]}\")\n",
    "    print(f\"Max: {results.minmax[1]}\")\n",
    "    print(f\"Mean: {results.mean}\")\n",
    "    print(f\"Variance: {results.variance}\")\n",
    "    print(f\"Skewness: {results.skewness}\")\n",
    "    print(f\"Kurtosis: {results.kurtosis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = [group for name, group in gbif.groupby(\"species\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian density-based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get the counts _per grid cell_ (with no radius applied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros(target_shape, dtype=int)\n",
    "\n",
    "points = np.c_[species.geometry.x, species.geometry.y]\n",
    "\n",
    "def increment_counts(point: np.ndarray) -> np.ndarray:\n",
    "    row, col = src.index(point[0], point[1])\n",
    "    counts[row, col] += 1\n",
    "    return counts\n",
    "\n",
    "for point in points:\n",
    "    increment_counts(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements: 1389930000\n",
      "Min: 0\n",
      "Max: 761\n",
      "Mean: 0.00010582691214665487\n",
      "Variance: 0.005251182749459388\n",
      "Skewness: 4017.2032220501437\n",
      "Kurtosis: 24062862.80862101\n"
     ]
    }
   ],
   "source": [
    "print_stats(counts.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the counts within a certain radius using `scipy.ndimage.gaussian_filter`. `sigma` is used to simulate the search radius, and so should be set to the desired radius / grid cell resolution. In this case, we're using the 20m Sentinel-2 grid and want to look at a 1km radius, so `sigma` = 1000 / 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = gaussian_filter(counts, sigma=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements: 1389930000\n",
      "Min: 0\n",
      "Max: 0\n",
      "Mean: 0.0\n",
      "Variance: 0.0\n",
      "Skewness: nan\n",
      "Kurtosis: nan\n"
     ]
    }
   ],
   "source": [
    "print_stats(counts.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "The statistics of the resulting counts array after applying the `gaussian_filter` suggest that this perhaps isn't the best approach. We would expect a maximum value of at least the max of the per-grid-cell counts, if not higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional approach using CuPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only did the Gaussian filter not work, it required long compute time (~10 mins). This isn't feasible when we need to process all ~9,200 species across 4 radii and two resolution sets. Due to similar restrictions, a 2D convolution also takes a long time, though at least returns usable results.\n",
    "\n",
    "To overcome the computation restraints we can use CuPy to take advantage of GPU availability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros(target_shape, dtype=int)\n",
    "\n",
    "points = np.c_[species.geometry.x, species.geometry.y]\n",
    "\n",
    "def increment_counts(point: np.ndarray) -> np.ndarray:\n",
    "    row, col = src.index(point[0], point[1])\n",
    "    counts[row, col] += 1\n",
    "    return counts\n",
    "\n",
    "for point in points:\n",
    "    increment_counts(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel-based counts - non-weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply a `scipy.signal.convolve_2d` with a binary radial kernel of our desired radius in grid cells (i.e. radius / resolution). The values of the cells that fall within the kernel then are multiplied by the kernel values and summed, giving us a sum of the counts in each of the neighboring grid cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard radial kernel:\n",
      "\n",
      "[[0 0 0 1 0 0 0]\n",
      " [0 1 1 1 1 1 0]\n",
      " [0 1 1 1 1 1 0]\n",
      " [1 1 1 1 1 1 1]\n",
      " [0 1 1 1 1 1 0]\n",
      " [0 1 1 1 1 1 0]\n",
      " [0 0 0 1 0 0 0]]\n",
      "\n",
      "Weighted radial kernel:\n",
      "\n",
      "[[0.   0.   0.   0.14 0.   0.   0.  ]\n",
      " [0.   0.17 0.33 0.41 0.33 0.17 0.  ]\n",
      " [0.   0.33 0.64 0.8  0.64 0.33 0.  ]\n",
      " [0.14 0.41 0.8  1.   0.8  0.41 0.14]\n",
      " [0.   0.33 0.64 0.8  0.64 0.33 0.  ]\n",
      " [0.   0.17 0.33 0.41 0.33 0.17 0.  ]\n",
      " [0.   0.   0.   0.14 0.   0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "\n",
    "def radial_kernel(radius: int, weighted: bool = False, sigma: Optional[float | int] = None) -> np.ndarray:\n",
    "    sigma = radius * 0.5 if sigma is None else sigma\n",
    "    y, x = np.ogrid[-radius : radius + 1, -radius : radius + 1]\n",
    "    distances_squared = x**2 + y**2\n",
    "    \n",
    "    if weighted:\n",
    "        kernel = np.exp(-distances_squared / (2*sigma**2))\n",
    "        kernel[distances_squared > radius**2] = 0\n",
    "        return kernel\n",
    "    \n",
    "    kernel = x**2 + y**2 <= radius**2\n",
    "    return kernel.astype(int)\n",
    "\n",
    "print(\"Standard radial kernel:\\n\")\n",
    "print(radial_kernel(3))\n",
    "print(\"\\nWeighted radial kernel:\\n\")\n",
    "print(radial_kernel(3, True).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize CuPy arrays on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 1000 // 20\n",
    "counts_gpu = cp.asarray(counts)\n",
    "kernel_gpu = cp.asarray(radial_kernel(radius))\n",
    "gauss_kernel_gpu = cp.asarray(radial_kernel(radius, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "radial_counts_gpu = cpx.scipy.signal.convolve2d(counts_gpu, kernel_gpu, mode=\"same\")\n",
    "radial_counts_wt_gpu = cpx.scipy.signal.convolve2d(counts_gpu, gauss_kernel_gpu, mode=\"same\")\n",
    "\n",
    "# Execution takes around 48 seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple counts:\n",
      "\n",
      "Number of elements: 1389930000\n",
      "Min: 0\n",
      "Max: 1224\n",
      "Mean: 0.8293358622376666\n",
      "Variance: 64.25457581424405\n",
      "Skewness: 44.16730926029975\n",
      "Kurtosis: 3144.4324769964023\n",
      "\n",
      "Weighted counts:\n",
      "\n",
      "Number of elements: 1389930000\n",
      "Min: 0.0\n",
      "Max: 762.1210812696761\n",
      "Mean: 0.35890692310931116\n",
      "Variance: 15.234865110079596\n",
      "Skewness: 55.578068616486235\n",
      "Kurtosis: 5052.684645513648\n"
     ]
    }
   ],
   "source": [
    "radial_counts = cp.asnumpy(radial_counts_gpu)\n",
    "radial_counts_wt = cp.asnumpy(radial_counts_wt_gpu)\n",
    "print(\"Simple counts:\\n\")\n",
    "print_stats(radial_counts.flatten())\n",
    "print(\"\\nWeighted counts:\\n\")\n",
    "print_stats(radial_counts_wt.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And lastly we can get binary counts by simply converting the `radial_counts` array to `bool` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "presence = radial_counts.astype(bool)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
